## demand paging

메모리 관리 메커니즘을 사용해서 여러 프로세스가 시스템의 메모리를 효율적으로 공유할 수 있도록 하는 기술



지금까지 메커니즘의 특징

MMU 가 도입됨으로 물리 메모리와는 별도로 논리 메모리가 도입됨. 피지컬 메모리는 시스템마다, 실행마다 변화하는데 이 피지컬 메모리와 무관한 가상 메모리가 도입되는게 가장 큰 특징이다.

이는 논리적인 주소 공간을 물리적은 주소공간으로 변환할 수 있음을 나타낸다.

지금 까지는 어떤 유저 프로그램이 시스템상에서 동작하려면 프로그램이 필요로하는 세그먼트들이 모두 피지컬 메모리에 있어야 한다는 가정 하에 설명했다. 하지만 실제로 이것은 불필요한 작업이다. 프로그램은 지역성을 가지고 있기 때문이다.



지역성의 원리

프로그램이 가장 최근에 접근했던 데이터를 다시 접근하거나(temporal locality) 최근에 참조했던 데이터 근처의 주소를 참조하는(spatial locality) 경향이 있다. why? 90/10 rule. 불과 10%의 코드가 프로그램 총 수행시간의 90%를 차지한다. loop 때문에.



현재 피지컬 메모리에 있지 않은 로지컬 메모리들은 스왑 디바이스에 위치한다. 스왑은 파일과 비교할 수 있다. 실제 파일에 접근하는 연산은 운영체제의 많은 기능을 사용한다. 즉 파일에 접근하는것은 무거운 작업이다.(오래 걸린다). 하지만 스왑에 접근하는것은 파일에 비해 빠른 접근이 가능하다. 예외적으로 스왑 디바이스가 가득 차는 경우 파일을 만들어서 페이지들을 저장할 수도 있다.



swap area(swap device)

피지컬 메모리에 저장되지 못한 페이지들을 저장하는 디스크 공간으로 파일에 비해 운영체제가 직접 빠르게 접근할수 있다.



피지컬 메모리에서 스왑 디바이스로 write back 하는 일이 언제 발생하는가?

새로운 페이지를 만들어서 피지컬 메모리에 저장해야 하는데 빈 공간이 없고, 피지컬 메모리에서 쫓아내려는 페이지가 dirty 페이지인 경우



스왑 디바이스에 대한 접근이 파일보다는 빠르다고는 해도 여전히 느린 작업이다. 따라서 메모리와 스왑디바이스간의 데이터 전송을 최대한 줄이는것이 좋다.

demand paging policy 의  목적

피지컬 메모리와 스왑 디바이스 사이의 데이터 전송이 최소한으로 발생하도록 해야한다.



메모리 엑세스 레이턴시 비교

레지스터(1 사이클) < L1 캐시(수 사이클) < L2 캐시(수십 사이클) < 메인 메모리(수백 사이클) < 디스크(수백만 사이클)



Thrashing

프로세스들이 사용하는 페이지들의 크기보다 사용 가능한 피지컬 메모리의 크기가 작을 때, 사용하려고 스왑 인 하는 페이지에 의해 앞으로 사용할 페이지가 스왑 아웃 되면서 반복적으로 페이지 폴트가 일어나는 현상. (어느 임계점을 넘으면 성능이 기하급수적으로 하락한다)



지금까지의 물리 주소는 LAM 상의 주소만을 가리켰지만 지금부터는 입출력 장치, 스왑 디바이스도 고려해야 한다.



이상적인 demand paging 의 동작

앞으로 사용될 페이지와 사용되지 않을 페이지를 미리 알아서 피지컬 메모리로 불러들이거나 스왑 디바이스로 내보내는 것



residence bit

대상 페이지가 피지컬 메모리에 있는지 스왑 디바이스에 있는지를 표시하는 페이지 테이블의 플래그 비트



## page fault handling

page fault: 버추얼 어드레스가 가리키는 페이지가 피지컬 메모리에 없어서 프로세스가 더 이상 진행할 수 없는 상태를 운영체제에게 알려주는 SW 인터럽트. 타겟 페이지가 residente 하지 않는 경우 발생.



page fault handler 의 동작

1. DMA controller 에게 해당 페이지의 주소를 전달
2. DMA controller 는 해당 페이지를 피지컬 메모리로 로드

page fault 의 처리가 다른 인터럽트에 비해 어려운 이유

수행 중인 인스트럭션에 의해 변화된 상태를 되돌렸다가 페이지 폴트 처리가 끝난 후 해당 인스트럭션을 재개해야 하기 때문   



## demand paging issue

- page selection policy
  - 페이지를 필요로 할 때 어떤 페이지를 어떤 순서로 가져오럭ㄴ가
- page replacement policy
  - 램이 꽉 찼을 때 어느 페이지를 버리는가
- page replacement style
  - global vs local
- page placement style
  - static vs dynamic





**page selection policy**

이상적인 페이지 선택 정책

앞으로 사용될 페이지를 미리 메인 메모리르 가져와서 페이지 폴트가 발생하지 않도록 하는 것



pure demand paging

프로세스가 시작할 때 0 개의 페이지로 시작. 프로세스가 수행되면서 필요로 하는 페이지를 계속 메인 메모리로 로드. 프로세스가 시작될 때 오랜 시간이 소요된다. 

solution: prepaging

앞으로 사용될 페이지를 예측해서 미리 메인 메모리로 로드하는 기법

효과적인 prepaging 방안

spatial locality 에 기반하여 페이지 폴트가 발생한 근처에 있는 페이지들을 메인 메모리에 로드.

Request paging(overlay)

논리적으로 연관성이 있는 페이지들을 미리 메인 메모리로 로드하는 기법



**page replacement policy**

- random: 하드웨어로 구현시 좋은 성능.
- fifo: 시작부터 끝까지 동작해야하는 프로세스가 단순히 로드된지 오래됐다고 교체대상이 되는것은 좋은 정책이 아니다.
- opt: 최적화
- LRU: 최근 가장 사용되지 않은 페이지 교체. 시간적 지역성에 기반한 페이지 교체 정책.
  - reference bit(use bit): 메인 메모리에 로드된 페이지가 엑세스되면 set 되는 비트 플래그. 



belady's anomaly

메모리를 늘렸음에도 불구하고 페이지 폴트가 더 많이 발생하는 현상



stack algorithm

n개의 frame 으로 구성된 메모리에 로드된 페이지들이 항상 N+1 개의 프레임으로 구성된 메모리에 로드된 페이지들의 부분집합이 되는 알고리즘. belady's anomaly 가 절대 발생하지 않음.

대표적으로 LRU



LRU approximation

- clock algorithm
  - clock hand 가 가리키는 page 의 reference bit 가 1인 경우, 0으로 바꾸고 clock hand 가 다음 페이지를 가리키도록 한다. 이 과정을 반복하다가 레퍼런스 비트가 0인 페이지를 만나면 해당 페이지를 교체한다.
 
 reference bit 가 제공되지 않을 경우에는 FIFO 기법을 사용한다. 하지만 FIFO 의 경우 먼저 할당된 페이지가 무조건 먼저 해제된다는 문제가 있기 때문에 메모리 관리 기법으로는 적합하지 않다. 따라서 FIFO 의 대안으로 frame buffering 이 사용된다.
 
 **frame buffering**
 
 사용중인 페이지(used page frame)와 가용 페이지(free page frame)가 연결리스트로 구현되어 있음.
 
 새로 할당되는 메모리는 먼저 가용 페이지에서 페이지를 할당받음.
 
 page replacement style
 
 - global replacement
   - 모든 페이지가 단일 replacement pool 에 들어가 있다.
   - 각각의 프로세스는 페이지 프레임에 대해 다른 프로세스들과 경쟁한다.
   - 메모리를 지나치게 사용하는 프로세스가 있다면 전체에게 악영향을 끼친다.
 - per-process replacement
   - 각각의 프로세스는 자신의 페이지 풀을 가지고 있다.
   - 프로세스에서 페이지 폴트가 발생하면 해당 프로세스의 페이지 풀 대에서만 교체 가능하다.
   - 운영체제는 단위 시간 동안 page fault 발생 횟수를 확인하여 프로세스의 메모리가 부족한지를 확인할 수 있다.
 - per-job replacement
   - 유저 단위로 페이지 풀을 할당받는다. 